{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f80d98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import io, transforms\n",
    "from torchvision.utils import Image, ImageDraw\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8fde7e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2508, 1906])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open('/scratch/st-singha53-1/datasets/geomx/dkd/geomx_pngs/disease1B_scan/disease1B_scan - 001.png').convert('RGB')\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()])\n",
    "img = transform(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46df4cc7",
   "metadata": {},
   "source": [
    "#### Channels:\n",
    "- FITC/525 nm : SYTO 13 : DNA (Grey)\n",
    "- Cy3/568 nm : Alexa 532 : PanCK (Yellow)\n",
    "- Texas Red/615 nm : Alexa 594 : CD45 (Cyan)\n",
    "- Cy5/666 nm : Cy5 : Custom (Magenta)\n",
    "\n",
    "**SYTO** Deep Red Nucleic Acid Stain is cell-permeant dye that specifically stains the nuclei of live, dead, or fixed cells.\n",
    "\n",
    "**pan-CK** (AE1/AE3) and EMA are epithelium-specific antibodies. As the basic component of cellular structure of normal epithelial cells and epithelial cancer cells, they are often used to differentiate tumors according to whether they originate from the epithelium or not.\n",
    "\n",
    "**CD45** is a signalling molecule that is an essential regulator of T and B cell antigen receptor signalling.\n",
    "**CD10+CD31** â€“ Proximal nephrons and endothelial cells (Custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dd974cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(dict_images, n_patches = 9, ref_group = 'normal'):\n",
    "    PATCH_SIZE = 256\n",
    "    f = int(np.sqrt(n_patches))\n",
    "    IMG_SIZE = PATCH_SIZE * f\n",
    "    resize = transforms.Resize((IMG_SIZE, IMG_SIZE))\n",
    "    transform = transforms.Compose([\n",
    "      transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    images = {}\n",
    "    for group in dict_images.keys():\n",
    "        dataset = []\n",
    "        for img in dict_images[group]:\n",
    "            ## import image\n",
    "            img = Image.open('geomx_data/'+img+'.png').convert('RGB')\n",
    "            ## convert img to tensor\n",
    "            img = transform(img)\n",
    "            ## resize image\n",
    "            resized_img = resize(img)\n",
    "            ## create patches\n",
    "            patches = resized_img.unfold(1, PATCH_SIZE, PATCH_SIZE).unfold(2, PATCH_SIZE, PATCH_SIZE)\n",
    "            ## reshape data\n",
    "            for i in range(f):\n",
    "                for j in range(f):\n",
    "                    sub_img = patches[:, i, j]\n",
    "                    if group == ref_group:\n",
    "                        data_target = (sub_img, 0)\n",
    "                    else:\n",
    "                        data_target = (sub_img, 1)\n",
    "                    dataset.append(data_target)\n",
    "            images[group] = dataset\n",
    "    return images\n",
    "\n",
    "class Custom_Dataset(torch.utils.data.dataset.Dataset):\n",
    "    def __init__(self, _dataset):\n",
    "        self.dataset = _dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example, target = self.dataset[index]\n",
    "        return example, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "962fea73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['disease1B_scan - 002.png',\n",
       " 'disease1B_scan - 023.png',\n",
       " 'disease1B_scan - 024.png',\n",
       " 'disease1B_scan - 021.png',\n",
       " 'disease1B_scan - 006.png',\n",
       " 'disease1B_scan - 005.png',\n",
       " 'disease1B_scan - 004.png',\n",
       " 'disease1B_scan - 019.png',\n",
       " 'disease1B_scan - 016.png',\n",
       " 'disease1B_scan - 012.png',\n",
       " 'disease1B_scan - 022.png',\n",
       " 'disease1B_scan - 020.png',\n",
       " 'disease1B_scan - 001.png',\n",
       " 'disease1B_scan - 003.png',\n",
       " 'disease1B_scan - 007.png',\n",
       " 'disease1B_scan - 010.png',\n",
       " 'disease1B_scan - 015.png',\n",
       " 'disease1B_scan - 014.png',\n",
       " 'disease1B_scan - 017.png',\n",
       " 'disease1B_scan - 009.png',\n",
       " 'disease1B_scan - 013.png',\n",
       " 'disease1B_scan - 008.png',\n",
       " 'disease1B_scan - 018.png',\n",
       " 'disease1B_scan - 011.png']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "path_to_images = \"/scratch/st-singha53-1/datasets/geomx/dkd/geomx_pngs/disease1B_scan/\"\n",
    "onlyfiles = [f for f in listdir(path_to_images) if isfile(join(path_to_images, f))]\n",
    "\n",
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f1466515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(path_to_images, x, group, ref_group, n_patches):\n",
    "    PATCH_SIZE = 256\n",
    "    f = int(np.sqrt(n_patches))\n",
    "    IMG_SIZE = PATCH_SIZE * f\n",
    "    resize = transforms.Resize((IMG_SIZE, IMG_SIZE))\n",
    "    transform = transforms.Compose([\n",
    "     transforms.ToTensor()\n",
    "    ])\n",
    "    ## import image\n",
    "    img = Image.open(path_to_images+x).convert('RGB')\n",
    "    ## convert img to tensor\n",
    "    img = transform(img)\n",
    "    ## resize image\n",
    "    resized_img = resize(img)\n",
    "    ## create patches\n",
    "    patches = resized_img.unfold(1, PATCH_SIZE, PATCH_SIZE).unfold(2, PATCH_SIZE, PATCH_SIZE)\n",
    "    dataset=[]\n",
    "    ## reshape data\n",
    "    for i in range(f):\n",
    "        for j in range(f):\n",
    "            sub_img = patches[:, i, j]\n",
    "            if group == ref_group:\n",
    "                data_target = (sub_img, 0)\n",
    "            else:\n",
    "                data_target = (sub_img, 1)\n",
    "            dataset.append(data_target)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6abdf200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(dict_images={}, n_patches = 9, ref_group = 'normal', path_to_images=[]):\n",
    "    images = {}\n",
    "    for group in dict_images.keys():\n",
    "        for sample in dict_images[group]:\n",
    "            path = path_to_images+sample+\"/\"\n",
    "            onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "            l = [process_image(path, x, group, ref_group, n_patches) for x in onlyfiles]\n",
    "            flat_list = [item for sublist in l for item in sublist]\n",
    "            images[group] = flat_list\n",
    "    return images\n",
    "\n",
    "class Custom_Dataset(torch.utils.data.dataset.Dataset):\n",
    "    def __init__(self, _dataset):\n",
    "        self.dataset = _dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example, target = self.dataset[index]\n",
    "        return example, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d1387621",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {'dkd': ['disease1B_scan', 'disease2B_scan'],\n",
    "         'normal': ['normal2B_scan']}\n",
    "valid = {'dkd': ['disease3_scan'],\n",
    "         'normal': ['normal3_scan']}\n",
    "test = {'dkd': ['disease4_scan'],\n",
    "        'normal': ['normal4_scan']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d07c71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loader\n",
      "validation loader\n"
     ]
    }
   ],
   "source": [
    "path_to_images = \"/scratch/st-singha53-1/datasets/geomx/dkd/geomx_pngs/\"\n",
    "\n",
    "print(\"train loader\")\n",
    "train_datasets = create_datasets(dict_images = train, n_patches = 9, ref_group = 'normal', path_to_images=path_to_images)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=Custom_Dataset(train_datasets['dkd'] + train_datasets['normal']),\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=False)\n",
    "print(\"validation loader\")\n",
    "valid_datasets = create_datasets(dict_images = valid, n_patches = 9, ref_group = 'normal', path_to_images=path_to_images)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=Custom_Dataset(valid_datasets['dkd'] + valid_datasets['normal']),\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=False)\n",
    "print(\"test loader\")\n",
    "test_datasets = create_datasets(dict_images = test, n_patches = 9, ref_group = 'normal', path_to_images=path_to_images)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=Custom_Dataset(test_datasets['dkd'] + test_datasets['normal']),\n",
    "                                           batch_size=1,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bb31a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torchvision import models\n",
    "\n",
    "# Hyperparameters\n",
    "in_channel = 3\n",
    "num_classes = 2\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "net = models.alexnet()\n",
    "\n",
    "net.load_state_dict(torch.load('../alexnet-owt-4df8aa71.pth'))\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d1d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.classifier[6] = nn.Linear(4096, 2)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acb56a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "net.classifier[6].weight.requires_grad = True\n",
    "net.classifier[6].bias.requires_grad = True\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f52cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeeda1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "    _,pred = torch.max(out, dim=1)\n",
    "    return torch.sum(pred==labels).item()\n",
    "\n",
    "net.to(device)\n",
    "net.train()\n",
    "\n",
    "n_epochs = 50\n",
    "print_every = 10\n",
    "valid_loss_min = np.Inf\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total=0\n",
    "    print(f'Epoch {epoch}\\n')\n",
    "    for batch_idx, (data_, target_) in enumerate(train_loader):\n",
    "        data_, target_ = data_.to(device), target_.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(data_)\n",
    "        loss = criterion(outputs, target_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _,pred = torch.max(outputs, dim=1)\n",
    "        correct += torch.sum(pred==target_).item()\n",
    "        total += target_.size(0)\n",
    "        if (batch_idx) % 20 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n",
    "    train_acc.append(100 * correct / total)\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    print(f'\\\\ntrain-loss: {np.mean(train_loss):.4f}, train-acc: {(100 * correct/total):.4f}')\n",
    "    batch_loss = 0\n",
    "    total_t=0\n",
    "    correct_t=0\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for data_t, target_t in (valid_loader):\n",
    "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "            outputs_t = net(data_t)\n",
    "            loss_t = criterion(outputs_t, target_t)\n",
    "            batch_loss += loss_t.item()\n",
    "            _,pred_t = torch.max(outputs_t, dim=1)\n",
    "            correct_t += torch.sum(pred_t==target_t).item()\n",
    "            total_t += target_t.size(0)\n",
    "        val_acc.append(100 * correct_t/total_t)\n",
    "        val_loss.append(batch_loss/len(valid_loader))\n",
    "        network_learned = batch_loss < valid_loss_min\n",
    "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t/total_t):.4f}\\\\n')\n",
    "\n",
    "        \n",
    "        if network_learned:\n",
    "            valid_loss_min = batch_loss\n",
    "            torch.save(net.state_dict(), 'model.pt')\n",
    "            print('Improvement-Detected, save-model')\n",
    "    net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe08bc7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.title(\"Train-Validation Accuracy\")\n",
    "plt.plot(train_acc, label='train')\n",
    "plt.plot(val_acc, label='validation')\n",
    "plt.xlabel('num_epochs', fontsize=12)\n",
    "plt.ylabel('accuracy', fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "plt.ylim(0,110)\n",
    "plt.axhline(y=50, color='gray', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e942aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_t=0\n",
    "correct_t=0\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for data_t, target_t in (test_loader):\n",
    "        data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "        outputs_t = net(data_t)\n",
    "        loss_t = criterion(outputs_t, target_t)\n",
    "        batch_loss += loss_t.item()\n",
    "        _,pred_t = torch.max(outputs_t, dim=1)\n",
    "        correct_t += torch.sum(pred_t==target_t).item()\n",
    "        total_t += target_t.size(0)\n",
    "        print(pred_t.item(), target_t.item())\n",
    "        \n",
    "100 * correct_t/total_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9526d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
