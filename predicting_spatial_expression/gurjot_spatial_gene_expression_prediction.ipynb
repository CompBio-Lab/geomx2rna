{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bef16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import io, transforms\n",
    "from torchvision.utils import Image, ImageDraw\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e063264c",
   "metadata": {},
   "source": [
    "## import sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df67ecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('/scratch/st-singha53-1/datasets/geomx/dkd/geomx_pngs/disease1B_scan/disease1B_scan - 001.png').convert('RGB')\n",
    "transform = transforms.Compose([\n",
    " transforms.ToTensor()\n",
    "])\n",
    "img = transform(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2b83c8",
   "metadata": {},
   "source": [
    "#### Channels:\t\n",
    " - FITC/525 nm : SYTO 13 : DNA (Grey)\n",
    " - Cy3/568 nm : Alexa 532 : PanCK (Yellow)\n",
    " - Texas Red/615 nm : Alexa 594 : CD45 (Cyan)\n",
    " - Cy5/666 nm : Cy5 : Custom (Magenta)\n",
    "\n",
    "**SYTO** Deep Red Nucleic Acid Stain is cell-permeant dye that specifically stains the nuclei of live, dead, or fixed cells.\n",
    "\n",
    "**pan-CK** (AE1/AE3) and EMA are epithelium-specific antibodies. As the basic component of cellular structure of normal epithelial cells and epithelial cancer cells, they are often used to differentiate tumors according to whether they originate from the epithelium or not.\n",
    "\n",
    "**CD45** is a signalling molecule that is an essential regulator of T and B cell antigen receptor signalling.\n",
    "\n",
    "**CD10+CD31** â€“ Proximal nephrons and endothelial cells (Custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc726e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "to_pil_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926782aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('/scratch/st-singha53-1/datasets/geomx/dkd/geomx_pngs/disease1B_scan/disease1B_scan - 001.png').convert('RGB')\n",
    "transform = transforms.Compose([\n",
    " transforms.ToTensor()\n",
    "])\n",
    "img = transform(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pil_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa840e",
   "metadata": {},
   "source": [
    "## image resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4636e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 3\n",
    "IMG_SIZE = 256*f\n",
    "PATCH_SIZE = 256\n",
    "\n",
    "resize = transforms.Resize((IMG_SIZE, IMG_SIZE))\n",
    "resized_img = resize(img)\n",
    "resized_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf6f576",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pil_image(resized_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc8babc",
   "metadata": {},
   "source": [
    "## Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b600852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = resized_img.unfold(1, PATCH_SIZE, PATCH_SIZE).unfold(2, PATCH_SIZE, PATCH_SIZE)\n",
    "\n",
    "dataset = []\n",
    "\n",
    "fig, ax = plt.subplots(f, f, figsize=(16, 16))\n",
    "for i in range(f):\n",
    "    for j in range(f):\n",
    "        sub_img = patches[:, i, j]\n",
    "        dataset.append(sub_img.unsqueeze(0))\n",
    "        ax[i][j].imshow(to_pil_image(sub_img))\n",
    "        ax[i][j].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8990e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "!ls -lahtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b00f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "model = models.alexnet()\n",
    "model.load_state_dict(torch.load('alexnet-owt-4df8aa71.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8412f49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as npd\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import Saliency\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a339ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -P / https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
    "labels_path = 'imagenet_class_index.json'\n",
    "with open(labels_path) as json_data:\n",
    "    idx_to_labels = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904ad39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = dataset[0]\n",
    "\n",
    "output = model(input)\n",
    "output = F.softmax(output, dim=1)\n",
    "prediction_score, pred_label_idx = torch.topk(output, 1)\n",
    "\n",
    "pred_label_idx.squeeze_()\n",
    "predicted_label = idx_to_labels[str(pred_label_idx.item())][1]\n",
    "print('Predicted:', predicted_label, '(', prediction_score.squeeze().item(), ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026bba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IntegratedGradients object and get attributes\n",
    "integrated_gradients = IntegratedGradients(model)\n",
    "attributions_ig = integrated_gradients.attribute(input, target=pred_label_idx, n_steps=200)\n",
    "\n",
    "# create custom colormap for visualizing the result\n",
    "default_cmap = LinearSegmentedColormap.from_list('custom blue', \n",
    "                                                 [(0, '#ffffff'),\n",
    "                                                  (0.25, '#000000'),\n",
    "                                                  (1, '#000000')], N=256)\n",
    "\n",
    "\n",
    "# visualize the results using the visualize_image_attr helper method\n",
    "_ = viz.visualize_image_attr_multiple(np.transpose(attributions_ig.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                             np.transpose(input.squeeze().cpu().detach().numpy(), (1,2,0)),\n",
    "                             methods=[\"original_image\", \"heat_map\"],\n",
    "                             signs=['all', 'positive'],\n",
    "                             cmap=default_cmap,\n",
    "                             show_colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91592b18",
   "metadata": {},
   "source": [
    "## train ResNet with trian and validation set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22d6536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(dict_images, n_patches = 9, ref_group = 'normal'):\n",
    "    PATCH_SIZE = 256\n",
    "    f = int(np.sqrt(n_patches))\n",
    "    IMG_SIZE = PATCH_SIZE * f\n",
    "    resize = transforms.Resize((IMG_SIZE, IMG_SIZE))\n",
    "    transform = transforms.Compose([\n",
    "     transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    images = {}\n",
    "    for group in dict_images.keys():\n",
    "        dataset = []\n",
    "        for img in dict_images[group]:\n",
    "            ## import image\n",
    "            img = Image.open('geomx_data/'+img+'.png').convert('RGB')\n",
    "            ## convert img to tensor\n",
    "            img = transform(img)\n",
    "            ## resize image\n",
    "            resized_img = resize(img)\n",
    "            ## create patches\n",
    "            patches = resized_img.unfold(1, PATCH_SIZE, PATCH_SIZE).unfold(2, PATCH_SIZE, PATCH_SIZE)\n",
    "            ## reshape data\n",
    "            for i in range(f):\n",
    "                for j in range(f):\n",
    "                    sub_img = patches[:, i, j]\n",
    "                    if group == ref_group:\n",
    "                        data_target = (sub_img, 0)\n",
    "                    else:\n",
    "                        data_target = (sub_img, 1)\n",
    "                    dataset.append(data_target)\n",
    "            images[group] = dataset\n",
    "    return images\n",
    "\n",
    "class Custom_Dataset(torch.utils.data.dataset.Dataset):\n",
    "    def __init__(self, _dataset):\n",
    "        self.dataset = _dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example, target = self.dataset[index]\n",
    "        return example, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae403f4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "path_to_images = \"/scratch/st-singha53-1/datasets/geomx/dkd/geomx_pngs/disease1B_scan/\"\n",
    "onlyfiles = [f for f in listdir(path_to_images) if isfile(join(path_to_images, f))]\n",
    "\n",
    "onlyfiles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e4baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f3214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sread(filename: str):\n",
    "   \n",
    "    losd = [] \n",
    "\n",
    "    with open(filename) as csvfile:\n",
    "        \n",
    "        reader = csv.reader(csvfile, delimiter='\\t')\n",
    "        \n",
    "        for row in reader:\n",
    "            losd.append(row)\n",
    "\n",
    "    \n",
    "    return losd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08597e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_image_name(f):\n",
    "    \n",
    "    x = f.split()\n",
    "    image_type = x[0]\n",
    "    image_number = x[2][0:3]\n",
    "    \n",
    "    return image_type + \" \" + \"|\" + \" \" + image_number + \" \" + \"|\" + \" \" + \"Geometric Segment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87110311",
   "metadata": {},
   "outputs": [],
   "source": [
    "thetest1 = sread('Kidney_Q3Norm_TargetCountMatrix.txt')\n",
    "thetest1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c6ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eset = pd.read_csv('Kidney_Q3Norm_TargetCountMatrix.txt', delimiter=\"\\t\", index_col=\"TargetName\")\n",
    "eset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2222757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eset = pd.read_csv('Kidney_Q3Norm_TargetCountMatrix.txt', delimiter=\"\\t\", index_col=\"TargetName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde789a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[i for i in eset.index if i.startswith('FRM')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ea5226",
   "metadata": {},
   "outputs": [],
   "source": [
    "[predict_gene_exp(gene_name) for gene in list(eset.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eac4fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gene_exp(gene_name):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7402911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corresponding_gene_expression_number(image_name):\n",
    "    eset = pd.read_csv('Kidney_Q3Norm_TargetCountMatrix.txt', delimiter=\"\\t\", index_col=\"TargetName\")\n",
    "    x = change_image_name(image_name)\n",
    "    return eset[change_image_name(x)]['FRMD3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81844e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_name_in_list(f):\n",
    "    thetest1 = sread('Kidney_Q3Norm_TargetCountMatrix.txt')\n",
    "    image_name_list = thetest1[0]\n",
    "    x = change_image_name(f)\n",
    "    for image_name in image_name_list:\n",
    "        if (image_name == x):\n",
    "            return True\n",
    "    return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb793f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_list(loi):\n",
    "    newfiles = []\n",
    "    for i in loi:\n",
    "        if (is_image_name_in_list(i)):\n",
    "            newfiles.append(i)\n",
    "    return newfiles\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ded3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(path_to_images, image_name, group, ref_group):\n",
    "    ## import image\n",
    "    img = Image.open(path_to_images+image_name).convert('RGB')\n",
    "    ## convert img to tensor\n",
    "    img = transform(img)\n",
    "    ## resize image\n",
    "    resized_img = resize(img)\n",
    "    ## create patches\n",
    "    patches = resized_img.unfold(1, PATCH_SIZE, PATCH_SIZE).unfold(2, PATCH_SIZE, PATCH_SIZE)\n",
    "    dataset=[]\n",
    "    gene_num = corresponding_gene_expression_number(image_name)\n",
    "    ## reshape data\n",
    "    for i in range(f):\n",
    "        for j in range(f):\n",
    "            sub_img = patches[:, i, j]\n",
    "            data_target = (sub_img, gene_num)\n",
    "            dataset.append(data_target)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3e2322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(dict_images={}, n_patches = 9, ref_group = 'normal', path_to_images=[]):\n",
    "    PATCH_SIZE = 256\n",
    "    f = int(np.sqrt(n_patches))\n",
    "    IMG_SIZE = PATCH_SIZE * f\n",
    "    resize = transforms.Resize((IMG_SIZE, IMG_SIZE))\n",
    "    transform = transforms.Compose([\n",
    "     transforms.ToTensor()\n",
    "    ])\n",
    "    images = {}\n",
    "    for group in dict_images.keys():\n",
    "        for sample in dict_images[group]:\n",
    "            path = path_to_images+sample+\"/\"\n",
    "            onlyfiles = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "            selectedfiles = image_list(onlyfiles)\n",
    "            l = [process_image(path, image_name, group, ref_group) for image_name in selectedfiles]\n",
    "            flat_list = [item for sublist in l for item in sublist]\n",
    "            images[group] = flat_list\n",
    "    return images\n",
    "\n",
    "class Custom_Dataset(torch.utils.data.dataset.Dataset):\n",
    "    def __init__(self, _dataset):\n",
    "        self.dataset = _dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example, target = self.dataset[index]\n",
    "        return example, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {'dkd': ['disease1B_scan', 'disease2B_scan'],\n",
    "         'normal': ['normal2B_scan']}\n",
    "valid = {'dkd': ['disease3_scan'],\n",
    "         'normal': ['normal3_scan']}\n",
    "test = {'dkd': ['disease4_scan'],\n",
    "        'normal': ['normal4_scan']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16b8e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_images = \"/scratch/st-singha53-1/datasets/geomx/dkd/geomx_pngs/\"\n",
    "\n",
    "print(\"train loader\")\n",
    "train_datasets = create_datasets(dict_images = train, n_patches = 4, ref_group = 'normal', path_to_images=path_to_images)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=Custom_Dataset(train_datasets['dkd'] + train_datasets['normal']),\n",
    "                                   batch_size=1,\n",
    "                                   shuffle=False)\n",
    "\n",
    "print(\"validation loader\")\n",
    "valid_datasets = create_datasets(dict_images = valid, n_patches = 4, ref_group = 'normal', path_to_images=path_to_images)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=Custom_Dataset(valid_datasets['dkd'] + valid_datasets['normal']),\n",
    "                                   batch_size=1,\n",
    "                                   shuffle=False)\n",
    "\n",
    "print(\"test loader\")\n",
    "test_datasets = create_datasets(dict_images = test, n_patches = 4, ref_group = 'normal', path_to_images=path_to_images)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=Custom_Dataset(test_datasets['dkd'] + test_datasets['normal']),\n",
    "                                   batch_size=1,\n",
    "                                   shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5ee05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f623688",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "# Hyperparameters\n",
    "in_channel = 3\n",
    "num_classes = 2\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Model\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "net = models.alexnet()\n",
    "net.load_state_dict(torch.load('alexnet-owt-4df8aa71.pth'))\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2bd8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.classifier[6] = nn.Linear(4096, 1)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a86341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "net.classifier[6].weight.requires_grad = True\n",
    "net.classifier[6].bias.requires_grad = True\n",
    "net.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379bf528",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f941f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_, target_ = train_loader.dataset[0][0], train_loader.dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f8e2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8bf0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_, target_ = train_loader.dataset[0][0], train_loader.dataset[0][1]\n",
    "data_ = torch.FloatTensor(data_).unsqueeze(0)\n",
    "target_ = torch.FloatTensor(np.array(target_))\n",
    "data_, target_ = data_.to(device), target_.to(device)\n",
    "net.to(device)\n",
    "\n",
    "type(data_), type(target_), print(device)\n",
    "# outputs = net(data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5305839",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3541c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(data_)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff0458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "print_every = 10\n",
    "valid_loss_min = np.Inf\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "total_step = len(train_loader)\n",
    "net.train()\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total=0\n",
    "    print(f'Epoch {epoch}\\n')\n",
    "    for batch_idx, (data_, target_) in enumerate(train_loader):\n",
    "        data_ = torch.FloatTensor(data_)\n",
    "        target_ = torch.FloatTensor(np.array(target_))\n",
    "        data_, target_ = data_.to(device), target_.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(data_)\n",
    "        target_ = target_.to(torch.float)\n",
    "        loss = criterion(outputs, target_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    train_loss.append(running_loss/len(train_loader))\n",
    "    print(f'\\ntrain-loss: {np.mean(train_loss):.4f}')\n",
    "    batch_loss = 0\n",
    "    total_t=0\n",
    "    correct_t=0\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for data_t, target_t in (valid_loader):\n",
    "            data_t = torch.FloatTensor(data_t)\n",
    "            target_t = torch.FloatTensor(np.array(target_t))\n",
    "            data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "            outputs_t = net(data_t)\n",
    "            loss_t = criterion(outputs_t, target_t)\n",
    "            batch_loss += loss_t.item()\n",
    "            total_t += target_t.size(0)\n",
    "        val_loss.append(batch_loss/len(valid_loader))\n",
    "        network_learned = batch_loss < valid_loss_min\n",
    "        print(f'validation loss: {np.mean(val_loss):.4f}')\n",
    "\n",
    "        \n",
    "        if network_learned:\n",
    "            valid_loss_min = batch_loss\n",
    "            torch.save(net.state_dict(), 'model.pt')\n",
    "            print('Improvement-Detected, save-model')\n",
    "    net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d2c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548918a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.title(\"Train-Validation Accuracy\")\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(val_loss, label='validation')\n",
    "plt.xlabel('num_epochs', fontsize=12)\n",
    "plt.ylabel('MSE loss', fontsize=12)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba727e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "actual = []\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for data_t, target_t in (test_loader):\n",
    "        data_t = torch.FloatTensor(data_t)\n",
    "        target_t = torch.FloatTensor(np.array(target_t))\n",
    "        data_t, target_t = data_t.to(device), target_t.to(device)\n",
    "        outputs_t = net(data_t)\n",
    "        loss_t = criterion(outputs_t, target_t)\n",
    "        batch_loss += loss_t.item()\n",
    "        total_t += target_t.size(0)\n",
    "        pred.append(outputs_t.item())\n",
    "        actual.append(target_t.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f12b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#define data\n",
    "x = np.array(actual)\n",
    "y = np.array(pred)\n",
    "\n",
    "#find line of best fit\n",
    "a, b = np.polyfit(x, y, 1)\n",
    "\n",
    "#add points to plot\n",
    "plt.scatter(x, y, color='purple')\n",
    "\n",
    "#add line of best fit to plot\n",
    "plt.plot(x, a*x+b, color='steelblue', linestyle='--', linewidth=2)\n",
    "\n",
    "#add fitted regression equation to plot\n",
    "plt.text(40, 35, 'y = ' + '{:.2f}'.format(b) + ' + {:.2f}'.format(a) + 'x', size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0ba04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(actual, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0348bb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
